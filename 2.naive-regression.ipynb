{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT330 - 2. Naive linear model\n",
    "\n",
    "<span style=\"color:blue\"> **This notebook train a linear model on all the input features with no feature processing.\n",
    "This a basic baseline. Use this notebook to explore the steps of training a model** </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the useful python modules\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'https://raw.githubusercontent.com/brajard/MAT330-Practical-work/master/data/train.csv'\n",
    "data_train = pd.read_csv(train_filename)\n",
    "\n",
    "# Extract the predictor (but not the target -> data leakage)\n",
    "X = data_train.drop('target',axis=1, inplace=False)\n",
    "y = data_train['target']\n",
    "\n",
    "# Do the same with the test dataset\n",
    "test_filename = 'https://raw.githubusercontent.com/brajard/MAT330-Practical-work/master/data/test.csv'\n",
    "Xtest = pd.read_csv(test_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Use all the features with no preprocessing expect drop stormid which is not numerical\n",
    "Xin = X.drop('stormid', axis=1)\n",
    "Xin_test = Xtest.drop('stormid', axis=1)\n",
    "\n",
    "# Equalization of the types:\n",
    "Xin = Xin.astype(float)\n",
    "Xin_test = Xin_test.astype(float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train into Val/Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "np.random.seed(10)\n",
    "\n",
    "#Selects the different stormid to split into train/validation\n",
    "ids = shuffle(X.stormid.unique())\n",
    "\n",
    "#Take 80% for training\n",
    "limit_train = int(.8*len(ids))\n",
    "\n",
    "#Index of training/val\n",
    "idx_train = X.index[X.stormid.isin(ids[:limit_train])]\n",
    "idx_val = X.index[X.stormid.isin(ids[limit_train:])]\n",
    "\n",
    "#Split the dataset into train/validation\n",
    "X_train, y_train = Xin.loc[idx_train], y.loc[idx_train]\n",
    "X_val, y_val = Xin.loc[idx_val], y.loc[idx_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. No Standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input features are used with no transformation for learning\n",
    "X_train_scaled = X_train\n",
    "X_val_scaled = X_val\n",
    "X_test_scaled = Xin_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predict = reg.predict(X_val_scaled)\n",
    "plt.scatter(y_val,y_val_predict)\n",
    "plt.plot([0,140],[0,140],'-k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = reg.score(X_val_scaled,y_val)\n",
    "print('linear regression score: {:.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Predicting the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the name for the file (e.g. you last name + a name for you algo)\n",
    "name = 'naive_lin'\n",
    "\n",
    "y_test_predict = reg.predict(X_test_scaled)\n",
    "np.save('test_predict.' + name + '.npy',y_test_predict)\n",
    "\n",
    "#Send the file by email to julien.brajard@nersc.no to check the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
