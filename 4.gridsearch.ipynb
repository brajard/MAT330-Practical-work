{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT330 - 3. Try a linear model\n",
    "<span style=\"color:blue\"> ** In this notebook, we train several models with a set of hyperparameters** </span>\n",
    "\n",
    "<span style=\"color:red\"> ** - What is the best model you achieve? ** </span>\n",
    "\n",
    "<span style=\"color:red\"> ** - Could you try other hyperparameters/other scikit models to do better? See the sklearn documentation on the web** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Specify the categorical features\n",
    "categorical_features = ['basin','nature']\n",
    "\n",
    "\n",
    "train_filename = 'https://raw.githubusercontent.com/brajard/MAT330-Practical-work/master/data/train.csv'\n",
    "\n",
    "data_train = pd.read_csv(train_filename, dtype={cat: 'category' for cat in categorical_features})\n",
    "\n",
    "# Extract the predictor (but not the target -> data leakage)\n",
    "X = data_train.drop('target',axis=1, inplace=False)\n",
    "y = data_train['target']\n",
    "\n",
    "# Do the same with the test dataset\n",
    "test_filename = 'https://raw.githubusercontent.com/brajard/MAT330-Practical-work/master/data/test.csv'\n",
    "\n",
    "Xtest = pd.read_csv(test_filename, dtype={cat: 'category' for cat in categorical_features})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Several models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Some exemple of function to compute new features\n",
    "\n",
    "# compute the  max, mean and standard deviation of the wind inensity\n",
    "def compute_wind(df):\n",
    "    features_u = [name for name in df.columns if name.startswith('u_')]\n",
    "    features_v = [name for name in df.columns if name.startswith('v_')]\n",
    "    u = df.get(features_u)\n",
    "    v = df.get(features_v)\n",
    "    intensity = u.values**2 + v.values**2\n",
    "    \n",
    "    return df.assign(wind_mean = intensity.mean(axis=1),\n",
    "                     wind_std = intensity.std(axis=1),\n",
    "                    wind_max = intensity.max(axis=1))\n",
    "\n",
    "# Compute the max, average and standard deviation of the pressure\n",
    "def compute_zmean(df):\n",
    "    features_z = [name for name in df.columns if name.startswith('z_')]\n",
    "    z = df.get(features_z)\n",
    "    return df.assign(z_mean = z.mean(axis=1),\n",
    "                    z_std = z.std(axis=1),\n",
    "                    z_max = z.max(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#Feature processing (on image)\n",
    "X = compute_wind(X)\n",
    "X = compute_zmean(X)\n",
    "Xtest = compute_wind(Xtest)\n",
    "Xtest = compute_zmean(Xtest)\n",
    "\n",
    "#Features to use\n",
    "features = ['latitude', 'instant_t','longitude', 'windspeed',\n",
    "       'hemisphere', 'Jday_predictor', 'initial_max_wind',\n",
    "       'max_wind_change_12h','dist2land',\n",
    "            'wind_mean','wind_std','wind_max',\n",
    "            'z_mean','z_std','z_max']\n",
    "\n",
    "\n",
    "Xin = X.get(features)\n",
    "Xin_test = Xtest.get(features)\n",
    "\n",
    "\n",
    "\n",
    "# Dummy encoding of categorical features\n",
    "Xcat = pd.get_dummies(X[categorical_features],prefix=categorical_features)\n",
    "Xcat_test = pd.get_dummies(Xtest[categorical_features],prefix=categorical_features)\n",
    "\n",
    "# Concatenate encoded categorical feature to other features\n",
    "Xin = pd.concat([Xin,Xcat],axis=1)\n",
    "Xin_test = pd.concat([Xin_test,Xcat_test],axis=1)\n",
    "\n",
    "# Equalization of the types:\n",
    "Xin = Xin.astype(float)\n",
    "Xin_test = Xin_test.astype(float)\n",
    "\n",
    "print('Size of training set:',Xin.shape)\n",
    "print('Size of test set:',Xin_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train into Val/Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "np.random.seed(10)\n",
    "ids = shuffle(X.stormid.unique())\n",
    "\n",
    "#Take 80% for training\n",
    "limit_train = int(.8*len(ids))\n",
    "\n",
    "#Index of training/val\n",
    "idx_train = X.index[X.stormid.isin(ids[:limit_train])]\n",
    "idx_val = X.index[X.stormid.isin(ids[limit_train:])]\n",
    "\n",
    "X_train, y_train = Xin.loc[idx_train], y.loc[idx_train]\n",
    "X_val, y_val = Xin.loc[idx_val], y.loc[idx_val]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Standardization\n",
    "For all features, transform your data such that mean=0 and std=1 (on the training data), and use the same parameters for transforming the test data also. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(Xin_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Specify the models and hyperparameter grids\n",
    "You can try other models and other hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "param_grid_lasso = {'alpha':[0,0.1,1,10]} #Note: alpha=0 is eq. to standard linear regression\n",
    "param_grid_rf = {'n_estimators':[50,100,200], 'min_samples_split':[2,5], 'max_features':['auto','sqrt']}\n",
    "param_grid_gb = {'n_estimators':[50,100,200], 'min_samples_split':[2,5], 'max_features':['auto','sqrt']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. \"Grid-Search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "lassoreg = Lasso()\n",
    "params_lasso = pd.Series(ParameterGrid(param_grid_lasso))\n",
    "score = pd.Series (np.nan,params_lasso.index)\n",
    "for i in params_lasso.index:\n",
    "    #Set the hyperparameters to the tested configuration\n",
    "    lassoreg.set_params(**params_lasso.loc[i])\n",
    "    \n",
    "    #Train the model\n",
    "    lassoreg.fit(X_train_scaled,y_train)\n",
    "    \n",
    "    #Compute the score\n",
    "    score.loc[i] = lassoreg.score(X_val_scaled,y_val)\n",
    "#Create a dataframe\n",
    "lasso_gs = pd.DataFrame({'params':params_lasso,'score':score})\n",
    "lasso_gs = lasso_gs.assign(regressor='lasso')\n",
    "lasso_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF regression\n",
    "rfreg = RandomForestRegressor()\n",
    "params_rf = pd.Series(ParameterGrid(param_grid_rf))\n",
    "score = pd.Series (np.nan,params_rf.index)\n",
    "for i in params_rf.index:\n",
    "    \n",
    "    #Set the hyperparameters to the tested configuration\n",
    "    rfreg.set_params(**params_rf.loc[i])\n",
    "    \n",
    "    #Train the model\n",
    "    rfreg.fit(X_train_scaled,y_train)\n",
    "    \n",
    "    #Compute the score\n",
    "    score.loc[i] = rfreg.score(X_val_scaled,y_val)\n",
    "    print(params_rf.loc[i],score.loc[i])\n",
    "#Create a dataframe\n",
    "rf_gs = pd.DataFrame({'params':params_rf,'score':score})\n",
    "rf_gs = rf_gs.assign(regressor='rf')\n",
    "rf_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF regression\n",
    "gbreg = GradientBoostingRegressor()\n",
    "params_gb = pd.Series(ParameterGrid(param_grid_gb))\n",
    "score = pd.Series (np.nan,params_gb.index)\n",
    "for i in params_gb.index:\n",
    "    \n",
    "    #Set the hyperparameters to the tested configuration\n",
    "    gbreg.set_params(**params_gb.loc[i])\n",
    "    \n",
    "    #Train the model\n",
    "    gbreg.fit(X_train_scaled,y_train)\n",
    "    \n",
    "    #Compute the score\n",
    "    score.loc[i] = gbreg.score(X_val_scaled,y_val)\n",
    "    print(params_gb.loc[i],score.loc[i])\n",
    "#Create a dataframe\n",
    "gb_gs = pd.DataFrame({'params':params_gb,'score':score})\n",
    "gb_gs = gb_gs.assign(regressor='gb')\n",
    "gb_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put all the results in the same dataframe\n",
    "gs_summary = pd.concat([lasso_gs,rf_gs,gb_gs],axis=0, ignore_index=True)\n",
    "gs_summary.sort_values('score',inplace=True,ascending=False)\n",
    "\n",
    "#Top 3 best regressors\n",
    "gs_summary.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Validate the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the best regressor\n",
    "best = gs_summary.iloc[0]\n",
    "if best.regressor == 'lasso':\n",
    "    reg = Lasso(**best.params)\n",
    "elif best.regressor == 'gb':\n",
    "    reg = GradientBoostingRegressor(**best.params)\n",
    "elif best.regressor == 'rf':\n",
    "    reg = RandomForestRegressor(**best.params)\n",
    "else:\n",
    "    print('Regressor',best.regressor,'not known')\n",
    "\n",
    "#Do one last fit\n",
    "reg.fit(X_train_scaled,y_train)\n",
    "y_val_predict = reg.predict(X_val_scaled)\n",
    "plt.scatter(y_val,y_val_predict)\n",
    "plt.plot([0,140],[0,140],'-k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = reg.score(X_val_scaled,y_val)\n",
    "print('linear regression score: {:.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Predicting the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change the name for the file (e.g. you last name, or a name for you algo)\n",
    "name = 'best_regressor'\n",
    "\n",
    "y_test_predict = reg.predict(X_test_scaled)\n",
    "np.save('test_predict.' + name + '.npy',y_test_predict)\n",
    "\n",
    "#Send the file by email to julien.brajard@nersc.no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns.values[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
