{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT330 - Practical work on Machine Learning\n",
    "<span style=\"color:blue\"> **This notebook load the data and explore quickly the different features:** </span>\n",
    "\n",
    "<span style=\"color:red\"> **- What is the target? ** </span>\n",
    "\n",
    "<span style=\"color:red\"> **- What are the qualitative features, quantitative features? ** </span>\n",
    "\n",
    "<span style=\"color:red\"> **- Which features are images? **</span>\n",
    "\n",
    "## Example : hurricane meteorological data\n",
    "\n",
    "Sophie Giffard-Roisin (sophie.giffard@univ-grenoble-alpes.fr)\n",
    "Julien Brajard (julien.brajard@nersc.no)\n",
    "\n",
    "## Introduction\n",
    "This is an initiation to introduce regression using machine learning and get you to know how it works.\n",
    "\n",
    "We will use a real hurricane meteorological dataset, which typical goal is to estimate the current stength of the hurricane or to predict its evolution. \n",
    "<img src=\"https://github.com/sophiegif/ramp_kit_storm_forecast_new/blob/master/figures_pynb/all_storms_since1979_IBTrRACKS_newcats.png?raw=true\" width=\"70%\">\n",
    "<div style=\"text-align: center\">Database: tropical/extra-tropical storm tracks since 1979. Dots = initial position, color = maximal storm strength according to the Saffir-Simpson scale.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "If you run the notebook on Colab, you don't have to install python libraries, but if you want to run the notebooks locally, you need to the followin modules:\n",
    "\n",
    "* numpy  \n",
    "* matplotlib\n",
    "* pandas \n",
    "* scikit-learn   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_filename = 'https://raw.githubusercontent.com/brajard/MAT330-Practical-work/master/data/train.csv'\n",
    "data_train = pd.read_csv(train_filename)\n",
    "\n",
    "# Extract the predictor (but not the target -> data leakage)\n",
    "X = data_train.drop('target',axis=1, inplace=False)\n",
    "y = data_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the same with the test dataset\n",
    "test_filename = 'https://raw.githubusercontent.com/brajard/MAT330-Practical-work/master/data/test.csv'\n",
    "Xtest = pd.read_csv(test_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 0D features from track data\n",
    "\n",
    "A set of simple features has been extracted for each storm at each time point: \n",
    "\n",
    "- latitude, longitude: in degrees\n",
    "- windspeed: current (max) windspeed (knots) \n",
    "- hemisphere:  South=0, North=1\n",
    "- Jday predictor:  Gaussian function of (Julian day of storm init - peak day of the hurricane season), see (1)\n",
    "- initial_max_wind: initial (max) windspeed of the storm \n",
    "- max_wind_change_12h: last 12h (max) windspeed change\n",
    "- basin = based on the present location: \n",
    "       0 = NA - North Atlantic / 1 = SA - South Atlantic    / 2 = WP - West Pacific       / 3 = EP - East Pacific /\n",
    "       4 = SP - South Pacific  / 5 = NI - North Indian      / 6 = SI - South Indian       / 7 = AS - Arabian Sea /\n",
    "       8 = BB - Bay of Bengal  / 9 = EA - Eastern Australia / 10 = WA - Western Australia / 11 = CP - Central Pacific\n",
    "       12 = CS - Carribbean Sea/ 13 = GM - Gulf of Mexico   / 14 = MM - Missing\n",
    "- nature = nature of the storm  \n",
    "       0 = TS - Tropical / 1 = SS - Subtropical / 2 = ET - Extratropical / 3 = DS - Disturbance /\n",
    "       4 = MX - Mix of conflicting reports / 5 = NR - Not Reported / 6 = MM - Missing / 7 =  - Missing\n",
    "- dist2land = current distance to the land (km)\n",
    "- target: 24h ahead windspeed (knots)\n",
    "\n",
    "\n",
    "(1) DeMaria, Mark, et al. \"Further improvements to the statistical hurricane intensity prediction scheme (SHIPS).\" Weather and Forecasting 20.4 (2005): 531-543. https://journals.ametsoc.org/doi/full/10.1175/WAF862.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The reanalysis data\n",
    "\n",
    "At each time step, we extracted 7 grids (11x11 pixels) of meteorological parameters centered on the current storm location. Their choice is based on the forecast literature, on personal experience and on known hypothesis of storm strengthening.\n",
    "\n",
    "#### a) 25x25 degree z, u and v at 700hPa-level\n",
    "First, we provide 3 maps of 25 x 25 degrees (lat/long) at 700hPa-level pressure: the altitude `z`, the u-wind `u` (positive if wind from the West) and the v-wind `v` (positive if wind from the South). These grids are subsampled to 11x11 pixels (1 pixel ~=2 degrees).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_z = X[[col for col in X.columns if col.startswith('z_')]]\n",
    "data_train_z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sample_id=20 # sample number plotted - you can change it to see other storms and other instants\n",
    "grid_l=11 # size of all 2D-grids (in pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_25x25=['z','u','v']\n",
    "plt.figure(figsize=(10,4))\n",
    "for p,param in enumerate(params_25x25):\n",
    "    image=np.zeros([grid_l,grid_l])\n",
    "    for i in range(grid_l):\n",
    "         for j in range(grid_l):\n",
    "            image[i,j]=X[param+'_'+str(i)+'_'+str(j)][sample_id]\n",
    "    plt.subplot(1,3,p+1)\n",
    "    plt.imshow(np.array(image),extent=[-12,12,-12,12],\n",
    "               interpolation='nearest', origin='lower', cmap='seismic')\n",
    "    plt.xlabel('param '+param)\n",
    "t=plt.suptitle('Example of 700-hPa level maps 25x25 degrees, centered in the storm location.'\n",
    "         +'\\n (altitude, u-wind and v-wind)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
